{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEihFnda5ZDc",
        "outputId": "a5087065-cd97-4994-d272-b31009e88768"
      },
      "outputs": [],
      "source": [
        "%pip install pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QQm1RuQtDq9w",
        "outputId": "bea4779d-8a57-4e94-b580-fbd4417e5a49"
      },
      "outputs": [],
      "source": [
        "%pip install -U sentence-transformers\n",
        "%pip install -U langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RM9BZcTe5dV3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "PINECONE_KEY = os.getenv('PINECONE_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_341Ep4P6SQj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Bruno\\Documents\\Universidad\\TACC\\tacc-pukyu-yachay\\venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pinecone = Pinecone(api_key=PINECONE_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktQmxXNmDVui"
      },
      "source": [
        "#Index Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5UrxqqpD3IAp"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "def create_or_use_index(index_name):\n",
        "  \"\"\"\n",
        "  Checks if the given index exists and creates it if it doesn't.\n",
        "\n",
        "  Args:\n",
        "      index_name: The name of the Pinecone index.\n",
        "\n",
        "  Returns:\n",
        "      The Pinecone index.\n",
        "  \"\"\"\n",
        "  if index_name in pinecone.list_indexes().names():\n",
        "    index = pinecone.Index(index_name)\n",
        "    print(f\"Found existing index: {index_name}\")\n",
        "  else:\n",
        "    print(f\"Creating new index: {index_name}\")\n",
        "    index = pinecone.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "        )\n",
        "  return index\n",
        "\n",
        "def delete_index(index_name):\n",
        "  \"\"\"\n",
        "  Deletes the given Pinecone index.\n",
        "\n",
        "  Args:\n",
        "      index_name: The name of the Pinecone index.\n",
        "  \"\"\"\n",
        "  if index_name in pinecone.list_indexes().names():\n",
        "    pinecone.delete_index(index_name)\n",
        "    print(f\"Deleted index: {index_name}\")\n",
        "  else:\n",
        "    print(f\"Index {index_name} does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SvaGRTrrBUk2"
      },
      "outputs": [],
      "source": [
        "index_name = 'pukyu-recetas'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV20TaKG794M",
        "outputId": "d257f78a-3332-4b73-e437-a7b8797cb4e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing index: pukyu-recetas\n"
          ]
        }
      ],
      "source": [
        "index = create_or_use_index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 260}},\n",
              " 'total_vector_count': 260}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Documents Preproccessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install chardet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chardet\n",
        "from typing import List, Tuple\n",
        "\n",
        "def preprocess_text_files(folder_path: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Lee y preprocesa archivos de texto de una carpeta, manejando diferentes codificaciones.\n",
        "\n",
        "    Args:\n",
        "    folder_path (str): Ruta a la carpeta que contiene los archivos de texto.\n",
        "\n",
        "    Returns:\n",
        "    List[Tuple[str, str]]: Una lista de tuplas, cada una conteniendo el nombre del archivo\n",
        "    y su contenido como una cadena de texto.\n",
        "    \"\"\"\n",
        "    processed_files = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            \n",
        "            # Leer el archivo en modo binario para detectar la codificación\n",
        "            with open(file_path, 'rb') as file:\n",
        "                raw_data = file.read()\n",
        "            \n",
        "            # Detectar la codificación\n",
        "            detected = chardet.detect(raw_data)\n",
        "            encoding = detected['encoding']\n",
        "\n",
        "            # Leer el archivo con la codificación detectada\n",
        "            try:\n",
        "                with open(file_path, 'r', encoding=encoding) as file:\n",
        "                    content = file.read()\n",
        "                \n",
        "                # Realizar cualquier limpieza o normalización adicional aquí\n",
        "                # Por ejemplo:\n",
        "                content = content.replace('\\r\\n', '\\n')  # Normalizar saltos de línea\n",
        "                content = ' '.join(content.split())  # Eliminar espacios múltiples\n",
        "                \n",
        "                processed_files.append((filename, content))\n",
        "                print(f\"Procesado: {filename} (Codificación: {encoding})\")\n",
        "            except UnicodeDecodeError:\n",
        "                print(f\"Error al decodificar: {filename}. Intentando con UTF-8.\")\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                        content = file.read()\n",
        "                    processed_files.append((filename, content))\n",
        "                    print(f\"Procesado con UTF-8: {filename}\")\n",
        "                except UnicodeDecodeError:\n",
        "                    print(f\"No se pudo procesar: {filename}\")\n",
        "\n",
        "    return processed_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesado: Cau_Cau_de_Pollo.txt (Codificación: utf-8)\n",
            "Procesado: Cañitas_fritas_rellenas_de_crema.txt (Codificación: utf-8)\n",
            "Procesado: Cebiche_de_Pollo.txt (Codificación: utf-8)\n",
            "Procesado: Champiñones_al_ajillo.txt (Codificación: utf-8)\n",
            "Procesado: Chanfainita.txt (Codificación: utf-8)\n",
            "Procesado: Charquican.txt (Codificación: utf-8)\n",
            "Procesado: Chicharrón_de_Pescado.txt (Codificación: utf-8)\n",
            "Procesado: Chili_con_carne.txt (Codificación: utf-8)\n",
            "Procesado: Chimichanga_dulce.txt (Codificación: utf-8)\n",
            "Procesado: Chipirones_a_la_plancha.txt (Codificación: utf-8)\n",
            "Procesado: Chipirones_encebollados.txt (Codificación: utf-8)\n",
            "Procesado: Choquitos_en_su_tinta.txt (Codificación: utf-8)\n",
            "Procesado: Chorizos_al_vino.txt (Codificación: utf-8)\n",
            "Procesado: Chorizos_a_la_sidra.txt (Codificación: utf-8)\n",
            "Procesado: Chuleta_de_cerdo_con_piperrada.txt (Codificación: utf-8)\n",
            "Procesado: Chupe_de_Camaroncito_Chino.txt (Codificación: utf-8)\n",
            "Procesado: Churros.txt (Codificación: utf-8)\n",
            "Procesado: Cochifrito.txt (Codificación: utf-8)\n",
            "Procesado: Cochinillo_asado_a_la_segoviana.txt (Codificación: utf-8)\n",
            "Procesado: Cocido_gallego.txt (Codificación: utf-8)\n",
            "Procesado: Cocochas_de_merluza_al_pil_pil.txt (Codificación: utf-8)\n",
            "Procesado: Codillo_asado_a_la_cerveza.txt (Codificación: utf-8)\n",
            "Procesado: Cogote_de_merluza_a_la_donostiarra.txt (Codificación: utf-8)\n",
            "Procesado: Conejo_al_ajo_cabañil.txt (Codificación: utf-8)\n",
            "Procesado: Conejo_a_la_cazadora.txt (Codificación: utf-8)\n",
            "Procesado: Congrio_con_fideos.txt (Codificación: utf-8)\n",
            "Procesado: Costillas_de_matanza.txt (Codificación: utf-8)\n",
            "Procesado: Costilla_asada.txt (Codificación: utf-8)\n",
            "Procesado: Costilla_de_cerdo_al_horno.txt (Codificación: utf-8)\n",
            "Procesado: Coulant_de_chocolate.txt (Codificación: utf-8)\n",
            "Procesado: Crema_catalana.txt (Codificación: utf-8)\n",
            "Procesado: Crema_de_calabaza.txt (Codificación: utf-8)\n",
            "Procesado: Crema_de_zanahoria.txt (Codificación: utf-8)\n",
            "Procesado: Crema_pastelera.txt (Codificación: utf-8)\n",
            "Procesado: Cristinas_con_nata_y_fresas.txt (Codificación: utf-8)\n",
            "Procesado: Croquetas_de_jamón.txt (Codificación: utf-8)\n",
            "Procesado: Donuts.txt (Codificación: utf-8)\n",
            "Procesado: Dorada_al_horno.txt (Codificación: utf-8)\n",
            "Procesado: Dorada_a_la_bilbaína.txt (Codificación: utf-8)\n",
            "Procesado: Dulce_de_leche_fácil.txt (Codificación: utf-8)\n",
            "Procesado: Empedrat.txt (Codificación: utf-8)\n",
            "Procesado: Ensaimada_mallorquina.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_Americana.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_campera.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_Caprese.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_César.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_de_ahumados_y_encurtidos.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_de_cherrys,_cebolleta_y_trigueros.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_de_langostinos_y_aguacate.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_de_pasta.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_de_pasta_y_salmón_ahumado.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_de_pimientos_asados.txt (Codificación: utf-8)\n",
            "Procesado: Ensalada_de_pimientos_con_ventresca.txt (Codificación: utf-8)\n",
            "Procesado: Ensaladilla_rusa.txt (Codificación: utf-8)\n",
            "Procesado: Escabeche_de_Pollo.txt (Codificación: utf-8)\n",
            "Procesado: Escalope_a_la_milanesa.txt (Codificación: utf-8)\n",
            "Procesado: Escalopines_al_Jerez.txt (Codificación: utf-8)\n",
            "Procesado: Espaguetis_a_la_carbonara.txt (Codificación: utf-8)\n",
            "Procesado: Espaguetis_a_la_napolitana.txt (Codificación: utf-8)\n",
            "Procesado: Espárragos_con_salsa_tártara.txt (Codificación: utf-8)\n",
            "Procesado: Espárragos_trigueros_con_panceta.txt (Codificación: utf-8)\n",
            "Procesado: Esqueixada.txt (Codificación: utf-8)\n",
            "Procesado: Estofado_de_pollo.txt (Codificación: utf-8)\n",
            "Procesado: Fabada_asturiana.txt (Codificación: utf-8)\n",
            "Procesado: Fabes_con_almejas.txt (Codificación: utf-8)\n",
            "Procesado: Fideos_con_almejas.txt (Codificación: utf-8)\n",
            "Procesado: Fideuá.txt (Codificación: utf-8)\n",
            "Procesado: Filete_Brasa_con_Arroz_Primavera.txt (Codificación: utf-8)\n",
            "Procesado: jiaco olluco.txt (Codificación: Windows-1252)\n",
            "Procesado: quy_receta_Ajiaco_de_Papa.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Ají_de_Gallina.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Alubias_estofadas_con_setas.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_a_banda.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_a_la_Jardinera_con_Pescado.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_caldero_murciano.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_con_bacalao.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_con_bogavante.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_con_Chancho_Lambayecano.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_con_leche.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_con_pollo.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Arroz_Tapado.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Berenjenas_rellenas_de_carne.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Brownies.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Bígaros_cocidos.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Caldeirada_de_raya.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Caldo_Verde.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Callos_a_la_madrileña.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Carne_ó_caldeiro.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Cau_Cau_de_Pollo.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Chipirones_a_la_plancha.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Churros.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Cocido_gallego.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Codillo_asado_a_la_cerveza.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Congrio_con_fideos.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Costilla_de_cerdo_al_horno.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Crema_catalana.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Crema_de_zanahoria.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Ensalada_de_pasta.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Ensalada_de_pimientos_asados.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Ensalada_de_pimientos_con_ventresca.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Espaguetis_a_la_napolitana.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Espárragos_trigueros_con_panceta.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Fabada_asturiana.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Fideos_con_almejas.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Gulas_con_gambas_al_ajillo.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Judías_verdes_con_chorizo.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Macedonia_de_frutas.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Mousse_de_chocolate.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Navajas_a_la_plancha.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Panna_cotta.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Patatas_a_la_riojana.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Pavo_Navideño_Relleno.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Pollo_al_Horno.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Pollo_al_Horno_Maggi_Brasa.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Pollo_a_la_Cerveza.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Pollo_guisado.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Pulpo_a_la_gallega.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Pulpo_encebollado.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Pulpo_á_feira.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Queso_frito.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Revuelto_de_bacalao_y_patata.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Richada_de_Forcarei.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Roscón_de_Pascua.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Salsa_Boloñesa.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Salsa_pico_de_gallo.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Seco_de_Pollo.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Sopa_de_fideos.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Taboulé_de_quinoa.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Tallarines_a_la_marinera.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Tallarines_Verdes_con_Maggi_Brasa.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Tarta_San_Marcos.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Terrina_de_pulpo.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Tocinillo_de_cielo.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Tortitas_de_nata.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Truchas_a_la_navarra.txt (Codificación: utf-8)\n",
            "Procesado: quy_receta_Vieiras_a_la_gallega.txt (Codificación: utf-8)\n",
            "Error al decodificar: receta_Ajiaco_de_Papa.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Ajiaco_de_Papa.txt\n",
            "Procesado: receta_Ají_de_Gallina.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Albóndigas_con_tomate.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Alcachofas_con_jamón.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Alcachofas_fritas.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_All_i_pebre.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Almejas_al_Albariño.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Almejas_a_la_marinera.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Almejas_en_salsa_verde.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Almejas_à_Bulhão_Pato.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Alubias_con_chorizo.txt (Codificación: None)\n",
            "Procesado: receta_Alubias_estofadas_con_setas.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Aros_de_cebolla_fritos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_a_banda.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_a_la_Jardinera_con_Pescado.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_a_la_milanesa.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_caldero_murciano.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_caldoso_con_nécoras.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_con_bacalao.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_con_berberechos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_con_bogavante.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_con_Carne.txt (Codificación: Windows-1252)\n",
            "Error al decodificar: receta_Arroz_con_Chancho_Lambayecano.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Arroz_con_Chancho_Lambayecano.txt\n",
            "Procesado: receta_Arroz_con_conejo.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_con_leche.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_con_Mariscos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_con_Pollo.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_negro.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_pilaf.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Arroz_Tapado.txt (Codificación: Windows-1254)\n",
            "Procesado: receta_Asadura_de_lechazo.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Atún_encebollado.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bacalao_a_la_gallega.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bacalao_a_la_portuguesa.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bacalao_con_fritada_de_cebolla_y_pimientos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bacalao_á_Bras.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Banana_split.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Banda_de_hojaldre_y_manzana.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Berberechos_al_vapor.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Berenjenas_rellenas_de_carne.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bica_mantecada.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bollos_suízos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bonito_con_salsa_de_tomate_y_ñoras.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Boquerones_en_vinagre.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Brazo_de_gitano.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Brownies.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bulgogi.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Buñuelos_de_bacalao_y_patata.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Bígaros_cocidos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Cachopo.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Cake_de_zanahoria_y_nueces.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Calamares_al_ajillo.txt (Codificación: ISO-8859-1)\n",
            "Procesado: receta_Calamares_rellenos_de_carne.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Caldeirada_de_raya.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Caldereta_de_cordero.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Caldereta_de_pescados_y_mariscos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Caldo_de_Gallina.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Caldo_de_Morón.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Caldo_gallego.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Caldo_Verde.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Callos_a_la_madrileña.txt (Codificación: Windows-1252)\n",
            "Error al decodificar: receta_Callos_con_garbanzos.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Callos_con_garbanzos.txt\n",
            "Procesado: receta_Canelones_de_San_Esteban.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Cangrejos_a_la_riojana.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Capón_estofado.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Carne_ó_caldeiro.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Carrilleras_de_ternera_al_vino_tinto.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Filloas.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Flamenquines.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Flan_de_café.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Flan_de_huevo.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Flores_de_carnaval.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Foie_con_boletus.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Foie_con_manzana.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Frejoles.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Fritura_a_la_andaluza.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Gambas_al_ajillo.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Gambas_a_la_plancha.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Garbanzos_con_chorizo_y_lacón.txt (Codificación: None)\n",
            "Procesado: receta_Gazpacho_andaluz.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Guacamole.txt (Codificación: Windows-1252)\n",
            "Error al decodificar: receta_Guiso_de_Carne.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Guiso_de_Carne.txt\n",
            "Error al decodificar: receta_Guiso_de_Pollo.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Guiso_de_Pollo.txt\n",
            "Procesado: receta_Guiso_de_Trigo_con_Pollo.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Gulas_al_ajillo.txt (Codificación: ascii)\n",
            "Procesado: receta_Gulas_con_gambas_al_ajillo.txt (Codificación: Windows-1252)\n",
            "Error al decodificar: receta_Huatia_con_Camote_Sancochado.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Huatia_con_Camote_Sancochado.txt\n",
            "Procesado: receta_Huevos_fritos_con_jamón.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Huevos_rellenos_de_atún_y_aceitunas.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Huevos_revueltos_con_trigueros_y_gambas.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Hummus.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Hígado_encebollado.txt (Codificación: Windows-1252)\n",
            "Error al decodificar: receta_Inchicapi_de_Gallina.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Inchicapi_de_Gallina.txt\n",
            "Procesado: receta_Jamón_asado.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Jarrete_estofado_al_vino_blanco.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Judías_verdes_con_chorizo.txt (Codificación: Windows-1254)\n",
            "Procesado: receta_Judías_verdes_con_tomate.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Lacón_con_grelos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Lamprea_a_la_bordelesa.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Langostinos_al_horno.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Langostinos_al_whisky.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Langostinos_cocidos.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Larpeira.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Lechazo_asado.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Leche_frita.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Lenguado_meunière.txt (Codificación: None)\n",
            "Error al decodificar: receta_Lentejas_estofadas.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Lentejas_estofadas.txt\n",
            "Error al decodificar: receta_Locro_con_Pollo.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Locro_con_Pollo.txt\n",
            "Procesado: receta_Lubina_a_la_espalda.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Lubina_a_la_sal.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Macarrones_con_carne.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Macarrones_con_tomate_y_ricotta.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Macedonia_de_frutas.txt (Codificación: Windows-1254)\n",
            "Procesado: receta_Madeleines.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Magdalenas.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Marmitako_de_bonito_del_norte.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Marmitako_de_caballa.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mejillones_al_vapor.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mejillones_a_la_marinera.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mejillones_a_la_vinagreta.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mejillones_en_escabeche.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mejillones_tigres.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Melón_con_jamón.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Merluza_a_la_cazuela.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Merluza_a_la_gallega.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Merluza_a_la_romana.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mermelada_de_higos.txt (Codificación: Windows-1252)\n",
            "Error al decodificar: receta_Migas_de_pastor.txt. Intentando con UTF-8.\n",
            "No se pudo procesar: receta_Migas_de_pastor.txt\n",
            "Procesado: receta_Moules_-_Frites.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mousse_de_chocolate.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mousse_de_limón.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mousse_de_mango.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Mousse_de_queso_Cebreiro.txt (Codificación: Windows-1252)\n",
            "Procesado: receta_Nachos_con_queso,_chile_y_cilantro.txt (Codificación: Windows-1252)\n"
          ]
        }
      ],
      "source": [
        "recepies_path = '../recetas_quy/'\n",
        "\n",
        "preprocessed_files = preprocess_text_files(recepies_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aSrTRXLDeNy"
      },
      "source": [
        "#Embeddings creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "2bkSEFKkDRiw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def process_documents_and_create_embeddings(\n",
        "    processed_documents: List[Tuple[str, str]],\n",
        "    model_name: str = 'all-MiniLM-L6-v2',\n",
        "    chunk_size: int = 100,\n",
        "    chunk_overlap: int = 20\n",
        ") -> Tuple[List[Dict[str, str]], List[List[float]]]:\n",
        "    \"\"\"\n",
        "    Procesa documentos preprocesados, los divide en chunks y crea embeddings.\n",
        "\n",
        "    Args:\n",
        "    processed_documents (List[Tuple[str, str]]): Lista de tuplas (nombre_archivo, contenido).\n",
        "    model_name (str): Nombre del modelo de SentenceTransformer a utilizar.\n",
        "    chunk_size (int): Tamaño máximo de cada chunk de texto.\n",
        "    chunk_overlap (int): Superposición entre chunks consecutivos.\n",
        "\n",
        "    Returns:\n",
        "    Tuple[List[Dict[str, str]], List[List[float]]]: Una tupla conteniendo la lista de chunks \n",
        "    (con metadatos) y la lista de sus embeddings correspondientes.\n",
        "    \"\"\"\n",
        "    # Inicializar el modelo de embedding\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    # Inicializar el divisor de texto\n",
        "    #text_splitter = RecursiveCharacterTextSplitter(\n",
        "    #    chunk_size=chunk_size,\n",
        "    #    chunk_overlap=chunk_overlap\n",
        "    #)\n",
        "\n",
        "    #all_chunks = []\n",
        "    all_texts = []\n",
        "\n",
        "    # Leer y procesar cada archivo en la carpeta\n",
        "    for filename, content in processed_documents:\n",
        "        #chunks = text_splitter.split_text(content)\n",
        "        #for chunk in chunks:\n",
        "        #    all_texts.append({\n",
        "        #        \"text\": chunk,\n",
        "        #        \"source\": filename\n",
        "        #    })\n",
        "        all_texts.append({\n",
        "            \"text\": content,\n",
        "            \"source\": filename\n",
        "        })\n",
        "\n",
        "    # Extraer solo el texto de los chunks para crear embeddings\n",
        "    texts = [text[\"text\"] for text in all_texts]\n",
        "\n",
        "    # Crear embeddings para todos los chunks\n",
        "    embeddings = model.encode(texts)\n",
        "\n",
        "    return all_texts, embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_texts, embeddings = process_documents_and_create_embeddings(preprocessed_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Uploading embeddings to Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "def upload_to_pinecone(\n",
        "    texts: List[str],\n",
        "    embeddings: List[List[float]],\n",
        "    batch_size: int = 100\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Sube chunks de texto y sus embeddings correspondientes a Pinecone.\n",
        "\n",
        "    Args:\n",
        "    chunks (List[str]): Lista de chunks de texto.\n",
        "    embeddings (List[List[float]]): Lista de embeddings correspondientes a los chunks.\n",
        "    batch_size (int): Tamaño del lote para las operaciones de upsert.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Verificar que el número de chunks y embeddings coincida\n",
        "    if len(texts) != len(embeddings):\n",
        "        raise ValueError(\"El número de chunks y embeddings debe ser el mismo.\")\n",
        "\n",
        "    # Preparar los datos para la subida\n",
        "    total_vectors = len(texts)\n",
        "    for i in range(0, total_vectors, batch_size):\n",
        "        batch_chunks = texts[i:i+batch_size]\n",
        "        batch_embeddings = embeddings[i:i+batch_size]\n",
        "        \n",
        "        # Crear IDs únicos para cada vector\n",
        "        ids = [str(uuid.uuid4()) for _ in range(len(batch_chunks))]\n",
        "        \n",
        "        # Preparar los vectores para el upsert\n",
        "        vectors_to_upsert = list(zip(ids, batch_embeddings, [{\"text\": chunk} for chunk in batch_chunks]))\n",
        "        \n",
        "        # Realizar el upsert\n",
        "        index.upsert(vectors=vectors_to_upsert)\n",
        "        \n",
        "        print(f\"Subidos {i+len(batch_chunks)} de {total_vectors} vectores\")\n",
        "\n",
        "    print(\"Subida completada.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subidos 100 de 260 vectores\n",
            "Subidos 200 de 260 vectores\n",
            "Subidos 260 de 260 vectores\n",
            "Subida completada.\n"
          ]
        }
      ],
      "source": [
        "texts = [file['text'] for file in all_texts]\n",
        "upload_to_pinecone(texts, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Testing the RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_llm_response(query: str, chunks: List[Dict[str, float]]) -> str:\n",
        "    \"\"\"\n",
        "    Simula la respuesta de un LLM basada en la consulta y los chunks recuperados.\n",
        "    \n",
        "    En un escenario real, esta función sería reemplazada por una llamada al modelo llama2-7b-hf.\n",
        "    \"\"\"\n",
        "    # Esta es una simulación muy básica\n",
        "    combined_context = \" \".join([chunk for chunk, _ in chunks])\n",
        "    response = f\"Basándome en la consulta '{query}' y el contexto proporcionado, \"\n",
        "    response += f\"puedo decir que la información relevante incluye {len(chunks)} fragmentos de texto. \"\n",
        "    response += f\"El contexto total tiene {len(combined_context)} caracteres. \"\n",
        "    response += \"Una respuesta más detallada se generaría utilizando el modelo LLM real.\"\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_rag(\n",
        "    query: str,\n",
        "    model_name: str = 'all-MiniLM-L6-v2',\n",
        "    top_k: int = 5\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Prueba el funcionamiento del RAG: recupera chunks relevantes y simula una respuesta.\n",
        "\n",
        "    Args:\n",
        "    query (str): La consulta del usuario.\n",
        "    api_key (str): API key de Pinecone.\n",
        "    environment (str): Entorno de Pinecone.\n",
        "    index_name (str): Nombre del índice de Pinecone a utilizar.\n",
        "    model_name (str): Nombre del modelo de SentenceTransformer a utilizar.\n",
        "    top_k (int): Número de chunks más relevantes a recuperar.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Inicializar el modelo de embedding\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    # Crear el embedding de la consulta\n",
        "    query_embedding = model.encode(query).tolist()\n",
        "\n",
        "    # Realizar la búsqueda en Pinecone\n",
        "    search_results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
        "\n",
        "    # Extraer los chunks y sus puntuaciones\n",
        "    retrieved_chunks = [\n",
        "        (result.metadata['text'], result.score) \n",
        "        for result in search_results.matches\n",
        "    ]\n",
        "\n",
        "    print(f\"Consulta: {query}\\n\")\n",
        "    print(\"Chunks recuperados:\")\n",
        "    for i, (chunk, score) in enumerate(retrieved_chunks, 1):\n",
        "        print(f\"\\nChunk {i} (Score: {score:.4f}):\")\n",
        "        print(chunk[:200] + \"...\" if len(chunk) > 200 else chunk)\n",
        "\n",
        "    # Simular la generación de respuesta\n",
        "    simulated_response = simulate_llm_response(query, retrieved_chunks)\n",
        "    \n",
        "    print(\"\\nRespuesta simulada del LLM:\")\n",
        "    print(simulated_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Consulta: ¿receta queso rawk asqa?\n",
            "\n",
            "Chunks recuperados:\n",
            "\n",
            "Chunk 1 (Score: 0.4487):\n",
            "receta marmitako bonito norte nisqa ingredientes qanchis pachak pichqa chunka gramo musuq bonito kilogramo papa huk clavo ajo huk unidad ch’uñu huk unidad italiano verde pimienta huk kuartal unidad pu...\n",
            "\n",
            "Chunk 2 (Score: 0.4252):\n",
            "receta quri horno ingredientes quri kilo soqta pachak gramo papa kimsa unidad clavokuna ajo huk unidad ch’uñu huk phatma puka pimentu huk phatma verde pimienta huk unidad limón huk cuchara perejil pha...\n",
            "\n",
            "Chunk 3 (Score: 0.4018):\n",
            "receta espárrago tartar salsa ingredientes iskay qutu yuraq espárrago iskay pachak pichqa chunka gramo tartar salsa kimsa litro yaku iskay limón unidad huk cuchara kachi instrucciones ñawpaqta yanapay...\n",
            "\n",
            "Chunk 4 (Score: 0.3994):\n",
            "receta Ensalada americana ingredientes huk uma k’uyusqa col huk uma romaine lechuga iskay unidad zanahoria huk unidad puka ch’uñu pusaq camarón unidad pusaq unidad cangrejo k’aspikuna iskay unidad sin...\n",
            "\n",
            "Chunk 5 (Score: 0.3992):\n",
            "receta verde habas tomate ingredientes huk kilo verde habas pichqa chunka gramo ch’uñu huk clavo ajo huk kuskan litro tomate salsa huk kuskan vaso aceitunas aceite huk ch’aqchuy yuraq vino huk k’allma...\n",
            "\n",
            "Respuesta simulada del LLM:\n",
            "Basándome en la consulta '¿receta queso rawk asqa?' y el contexto proporcionado, puedo decir que la información relevante incluye 5 fragmentos de texto. El contexto total tiene 4083 caracteres. Una respuesta más detallada se generaría utilizando el modelo LLM real.\n"
          ]
        }
      ],
      "source": [
        "test_query = \"¿receta queso rawk asqa?\"\n",
        "test_rag(test_query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ktQmxXNmDVui"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
